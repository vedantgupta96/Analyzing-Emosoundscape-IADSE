# -*- coding: utf-8 -*-
"""CS286-IADSE Dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DLWwfZclKyEp1Rd5I_T5l0639Whi-jGx
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
from sklearn import preprocessing
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler

import numpy as np
import seaborn as sns

!pip install -U -q PyDrive
!pip install scikit-plot
!pip install featurewiz

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)


downloaded = drive.CreateFile({'id':'1q1Ha1e9K9VJD8nCeggB8VKD4jN9UJaIN'}) # replace the id with id of file you want to access
downloaded.GetContentFile('IADSED.csv')

sound = pd.read_csv('IADSED.csv')
df = pd.DataFrame(sound)
nullCount = df.columns[df.isnull().any()]
# All the columns that have missing data are numeric, so I'm using the mean to fill the null values
df.fillna(df.mean(), inplace=True)
df_num = df.drop(df.loc[:, 'source':'BE_Classification'].columns, axis=1, inplace=False)
df.head()

# normalize the data attributes
scaler = MinMaxScaler()
scaledDf = pd.DataFrame(scaler.fit_transform(df_num),index=df_num.index, columns=df_num.columns, ) 

#fig, axs = plt.subplots(ncols=3,figsize=(90,20))
sns.scatterplot(data=scaledDf, x='dominance', y='arousal')

sns.scatterplot(data=scaledDf, x='valence', y='arousal')

sns.heatmap(scaledDf.corr(),cmap='RdYlGn')

dfPair = df.iloc[:, 4:8]
dfPair.head()
sns.pairplot(dfPair, hue="BE_Classification")

df1 = scaledDf[["arousal","dynamics_rms_mean"]]
corr = df1.corr()
corr.style.background_gradient(cmap='coolwarm')



# Splitting the dataset into training and testing data
from sklearn.model_selection import train_test_split
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_regression
from matplotlib import pyplot
X = scaledDf.iloc[:,scaledDf.columns != 'dominance'].values # these are factors for the prediction
X = scaledDf[['arousal', 'valence', 'dynamics_rms_mean', 'spectral_centroid_std',
       'spectral_skewness_mean', 'spectral_irregularity_mean',
       'spectral_inharmonicity_mean', 'spectral_mfcc_mean_1',
       'spectral_mfcc_mean_4', 'tonal_hcdf_std']].values
# X = scaledDf[['arousal', 'valence', 'dynamics_rms_std', 'rhythm_attacktime_mean',
#        'rhythm_eventdensity_mean', 'rhythm_fluctuationmax_peakposmean']].values
#X = scaledDf.iloc[:, [0] + [1] + list(range(3,71)) ].values
# X = scaledDf[['arousal', 'valence', 'dynamics_rms_std', 'rhythm_attacktime_mean',
#        'rhythm_tempo_mean', 'rhythm_tempo_std', 'rhythm_pulseclarity_mean',
#        'rhythm_eventdensity_mean', 'rhythm_fluctuationmax_peakposmean']].values
y = scaledDf.iloc[:,2].values # this is what we want to predict

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state=34)

def select_features(X_train, y_train, X_test):
	# configure to select all features
	fs = SelectKBest(score_func=f_regression, k=10)
	# learn relationship from training data
	fs.fit(X_train, y_train)
	# transform train input data
	X_train_fs = fs.transform(X_train)
	# transform test input data
	X_test_fs = fs.transform(X_test)
	return X_train_fs, X_test_fs, fs
# X_train, X_test, fs = select_features(X_train, y_train, X_test)
#X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, train_size=0.9)

from sklearn.svm import SVR
from sklearn.linear_model import LinearRegression
from sklearn import metrics
from sklearn.ensemble import RandomForestRegressor
import numpy as np
lr_model = LinearRegression()
lr_model.fit(X_train, y_train.ravel())
lr_model_train = lr_model.predict(X_train)
print(metrics.mean_squared_error(y_train, lr_model_train, squared=False)) #squared = False returns RMSE
lr_model_test = lr_model.predict(X_test)
print(metrics.mean_squared_error(y_test, lr_model_test, squared=False))

svrPoly = SVR(kernel="poly", C = 1, gamma="auto", degree=3, epsilon=0.1, coef0=1)

svrPoly.fit(X_train, y_train.ravel())
svr_model_train = svrPoly.predict(X_train)
print(metrics.mean_squared_error(y_train, svr_model_train, squared=False)) #squared = False returns RMSE
svr_model_test = svrPoly.predict(X_test)
print(metrics.mean_squared_error(y_test, svr_model_test, squared=False))

from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score


kf = KFold(n_splits=5)
list_training_error = []
list_testing_error = []
for train_index, test_index in kf.split(X):
  X_train, X_test = X[train_index], X[test_index] 
  y_train, y_test = y[train_index], y[test_index]
  svrPoly.fit(X_train, y_train)
  y_train_data_pred = svrPoly.predict(X_train)
  y_test_data_pred = svrPoly.predict(X_test)
  fold_training_error = metrics.mean_squared_error(y_train, y_train_data_pred,squared=False)
  fold_testing_error = metrics.mean_squared_error(y_test, y_test_data_pred,squared=False)
  list_training_error.append(fold_training_error)
  list_testing_error.append(fold_testing_error)

plt.subplot(1,2,1)
plt.plot(range(1, kf.get_n_splits() + 1), np.array(list_training_error).ravel(), 'o-')
plt.xlabel('number of fold') 
plt.ylabel('training error')
plt.title('Training error across folds')
plt.tight_layout()
plt.subplot(1,2,2)
plt.plot(range(1, kf.get_n_splits() + 1), np.array(list_testing_error).ravel(), 'o-')
plt.xlabel('number of fold')
plt.ylabel("testing error")
plt.title('Testing error across folds')
plt.tight_layout()
plt.show()

kf = KFold(n_splits=5)
list_training_error = []
list_testing_error = []
for train_index, test_index in kf.split(X):
  X_train, X_test = X[train_index], X[test_index] 
  y_train, y_test = y[train_index], y[test_index]
  lr_model.fit(X_train, y_train)
  y_train_data_pred = lr_model.predict(X_train)
  y_test_data_pred = lr_model.predict(X_test)
  fold_training_error = metrics.mean_squared_error(y_train, y_train_data_pred,squared=False)
  fold_testing_error = metrics.mean_squared_error(y_test, y_test_data_pred,squared=False)
  list_training_error.append(fold_training_error)
  list_testing_error.append(fold_testing_error)

plt.subplot(1,2,1)
plt.plot(range(1, kf.get_n_splits() + 1), np.array(list_training_error).ravel(), 'o-')
plt.xlabel('number of fold') 
plt.ylabel('training error')
plt.title('Training error across folds')
plt.tight_layout()
plt.subplot(1,2,2)
plt.plot(range(1, kf.get_n_splits() + 1), np.array(list_testing_error).ravel(), 'o-')
plt.xlabel('number of fold')
plt.ylabel("testing error")
plt.title('Testing error across folds')
plt.tight_layout()
plt.show()

# 5 fold Cross Validation

scores_arou_lr = cross_val_score(lr_model, X_test, y_test, cv=5)
scores_arou_poly = cross_val_score(svrPoly, X_test, y_test, cv=5)
print("%0.3f accuracy for Linear Regression with a standard deviation of %0.3f" % (scores_arou_lr.mean(), scores_arou_lr.std()))
print("%0.3f accuracy for Support Vector Regression with a standard deviation of %0.3f" % (scores_arou_poly.mean(), scores_arou_poly.std()))





# import sklearn.externals as extjoblib
# import joblib
# from sklearn.feature_selection import SequentialFeatureSelector as sfs
# from sklearn.linear_model import LinearRegression

# lreg = LinearRegression()
  
# sfs1 = sfs(lreg, n_features_to_select=10, direction='backward')
# sfs1 = sfs1.fit(X, y)
# indices = sfs1.get_support(indices=True)

import scikitplot as skplt
skplt.estimators.plot_learning_curve(lr_model, X, y,
                                     cv=7, shuffle=True,n_jobs=-1,
                                     figsize=(6,4), title_fontsize="large", text_fontsize="large", scoring='neg_root_mean_squared_error',
                                     title="Evaluation Metrics with Feature Selection for Linear Regression");
skplt.estimators.plot_learning_curve(svrPoly, X, y,
                                     cv=7, shuffle=True,n_jobs=-1,
                                     figsize=(6,4), title_fontsize="large", text_fontsize="large", scoring='neg_root_mean_squared_error',
                                     title="Evaluation Metrics with Feature Selection for SVR");

scaledDf

def label_class (row):
   if row['arousal'] <= 0.5 and row['valence'] <= 0.5:
      return 3
   if row['arousal'] <= 0.5 and row['valence'] > 0.5:
      return 4
   if row['arousal'] > 0.5 and row['valence'] <= 0.5:
      return 2
   if row['arousal'] > 0.5 and row['valence'] > 0.5:
      return 1
   return 'Other'

scaledDfClass = scaledDf

scaledDfClass['class_label'] = scaledDfClass.apply (lambda row: label_class(row), axis=1)

scaledDfClass

target = scaledDfClass['class_label']

ones = (target == 1).sum()
twos = (target == 2).sum()
threes = (target == 3).sum()
fours = (target == 4).sum()

print("Ones: {}\nTwos: {}\nThrees: {}\nFours: {}\n".format(ones, twos,threes,fours))

sns.scatterplot(scaledDfClass['valence'], scaledDfClass['arousal'])

plt.hist(scaledDfClass['class_label'])

from sklearn.linear_model import LogisticRegression
from featurewiz import featurewiz

# X = scaledDfClass.iloc[:,scaledDfClass.columns != 'class_label'].values # these are factors for the prediction
X = scaledDfClass.iloc[:,2:71].values
# X = scaledDfClass[['dominance',
#  'dynamics_rms_mean',
#  'spectral_rolloff85_mean',
#  'timbre_spectralflux_std',
#  'tonal_keyclarity_mean',
#  'tonal_keyclarity_std',
#  'spectral_rolloff85_std',
#  'tonal_hcdf_mean',
#  'tonal_mode_mean',
#  'spectral_mfcc_mean_2',
#  'spectral_roughness_mean',
#  'spectral_mfcc_std_10',
#  'spectral_mfcc_mean_1',
#  'spectral_mfcc_mean_5',
#  'tonal_mode_std',
#  'spectral_mfcc_mean_8']].values

y = scaledDfClass['class_label']
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state=76)
X

#features, train = featurewiz(scaledDfClass.iloc[:,2:72], 'class_label', verbose=2, sep=",", header=0,test_data="", feature_engg="", category_encoders="")

LogReg = LogisticRegression(max_iter=600)
LogReg.fit(X_train,y_train)

from sklearn.metrics import plot_confusion_matrix,classification_report

# LogReg.score(X,y)
model_train = LogReg.predict(X_train)
model_test = LogReg.predict(X_test)
print(LogReg.score(X_train,y_train))
print(LogReg.score(X_test,y_test))

color = 'white'
matrix = plot_confusion_matrix(LogReg, X_test, y_test, cmap=plt.cm.Blues)
matrix.ax_.set_title('Confusion Matrix', color=color)
plt.xlabel('Predicted Label', color='black')
plt.ylabel('True Label', color='black')
plt.gcf().axes[0].tick_params(colors='black')
plt.gcf().axes[1].tick_params(colors='black')
plt.show()
confusion_matrix = metrics.confusion_matrix(y_test, model_test)
confusion_matrix

report = classification_report(y_test, model_test,output_dict=True)
df_classification_report = pd.DataFrame(report).transpose()
df_classification_report

from sklearn.ensemble import RandomForestClassifier
rfModel = RandomForestClassifier(n_estimators = 8, random_state=24) 
rfModel.fit(X_train, y_train)
 
# performing predictions on the test dataset
y_pred = rfModel.predict(X_test)
print(rfModel.score(X_train,y_train))
print(rfModel.score(X_test,y_test))

from sklearn.metrics import plot_confusion_matrix

color = 'white'
matrix = plot_confusion_matrix(rfModel, X_test, y_test, cmap=plt.cm.Blues)
matrix.ax_.set_title('Confusion Matrix', color=color)
plt.xlabel('Predicted Label', color='black')
plt.ylabel('True Label', color='black')
plt.gcf().axes[0].tick_params(colors='black')
plt.gcf().axes[1].tick_params(colors='black')
plt.show()
confusion_matrix = metrics.confusion_matrix(y_test, y_pred)
confusion_matrix

report = classification_report(y_test, y_pred,output_dict=True)
df_classification_report = pd.DataFrame(report).transpose()
df_classification_report

from sklearn.neighbors import KNeighborsClassifier

knnModel = KNeighborsClassifier(n_neighbors=12)
knnModel.fit(X_train, y_train) 

# Predict y data with classifier: 
y_predict = knnModel.predict(X_test)
print(knnModel.score(X_train,y_train))
print(knnModel.score(X_test,y_test))

from sklearn.metrics import plot_confusion_matrix

color = 'white'
matrix = plot_confusion_matrix(knnModel, X_test, y_test, cmap=plt.cm.Blues)
matrix.ax_.set_title('Confusion Matrix', color=color)
plt.xlabel('Predicted Label', color='black')
plt.ylabel('True Label', color='black')
plt.gcf().axes[0].tick_params(colors='black')
plt.gcf().axes[1].tick_params(colors='black')
plt.show()
confusion_matrix = metrics.confusion_matrix(y_test, y_predict)
confusion_matrix

report = classification_report(y_test, y_predict,output_dict=True)
df_classification_report = pd.DataFrame(report).transpose()
df_classification_report

"""Feature Selection for classification"""

X = scaledDfClass[['dominance',
 'dynamics_rms_mean',
 'spectral_rolloff85_mean',
 'timbre_spectralflux_std',
 'tonal_keyclarity_mean',
 'tonal_keyclarity_std',
 'spectral_rolloff85_std',
 'tonal_hcdf_mean',
 'tonal_mode_mean',
 'spectral_mfcc_mean_2',
 'spectral_roughness_mean',
 'spectral_mfcc_std_10',
 'spectral_mfcc_mean_1',
 'spectral_mfcc_mean_5',
 'tonal_mode_std',
 'spectral_mfcc_mean_8']].values

y = scaledDfClass['class_label']
X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2,random_state=76)
X

#features, train = featurewiz(scaledDfClass.iloc[:,2:72], 'class_label', verbose=2, sep=",", header=0,test_data="", feature_engg="", category_encoders="")

from sklearn.metrics import plot_confusion_matrix,classification_report

LogReg = LogisticRegression(max_iter=600)
LogReg.fit(X_train,y_train)

# LogReg.score(X,y)
model_train = LogReg.predict(X_train)
model_test = LogReg.predict(X_test)
print(LogReg.score(X_train,y_train))
print(LogReg.score(X_test,y_test))

color = 'white'
matrix = plot_confusion_matrix(LogReg, X_test, y_test, cmap=plt.cm.Blues)
matrix.ax_.set_title('Confusion Matrix', color=color)
plt.xlabel('Predicted Label', color='black')
plt.ylabel('True Label', color='black')
plt.gcf().axes[0].tick_params(colors='black')
plt.gcf().axes[1].tick_params(colors='black')
plt.show()
confusion_matrix = metrics.confusion_matrix(y_test, model_test)
confusion_matrix

report = classification_report(y_test, model_test, output_dict=True)
df_classification_report = pd.DataFrame(report).transpose()
df_classification_report

from sklearn.ensemble import RandomForestClassifier
rfModel = RandomForestClassifier(n_estimators = 8, random_state=24) 
rfModel.fit(X_train, y_train)
 
# performing predictions on the test dataset
y_pred = rfModel.predict(X_test)
print(rfModel.score(X_train,y_train))
print(rfModel.score(X_test,y_test))



color = 'white'
matrix = plot_confusion_matrix(rfModel, X_test, y_test, cmap=plt.cm.Blues)
matrix.ax_.set_title('Confusion Matrix', color=color)
plt.xlabel('Predicted Label', color='black')
plt.ylabel('True Label', color='black')
plt.gcf().axes[0].tick_params(colors='black')
plt.gcf().axes[1].tick_params(colors='black')
plt.show()
confusion_matrix = metrics.confusion_matrix(y_test, y_pred)
confusion_matrix

report = classification_report(y_test, y_pred, output_dict=True)
df_classification_report = pd.DataFrame(report).transpose()
df_classification_report

from sklearn.neighbors import KNeighborsClassifier

knnModel = KNeighborsClassifier(n_neighbors=12)
knnModel.fit(X_train, y_train) 

# Predict y data with classifier: 
y_predict = knnModel.predict(X_test)
print(knnModel.score(X_train,y_train))
print(knnModel.score(X_test,y_test))


color = 'white'
matrix = plot_confusion_matrix(knnModel, X_test, y_test, cmap=plt.cm.Blues)
matrix.ax_.set_title('Confusion Matrix', color=color)
plt.xlabel('Predicted Label', color='black')
plt.ylabel('True Label', color='black')
plt.gcf().axes[0].tick_params(colors='black')
plt.gcf().axes[1].tick_params(colors='black')
plt.show()
confusion_matrix = metrics.confusion_matrix(y_test, y_predict)
confusion_matrix

report = classification_report(y_test, y_predict, output_dict=True)
df_classification_report = pd.DataFrame(report).transpose()
df_classification_report